{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0087c134",
   "metadata": {},
   "source": [
    "### Data Fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fa3ac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"coastalcph/tydi_xor_rc\")\n",
    "languages = ['ar', 'ko', 'te', 'en']\n",
    "train_dataset = dataset[\"train\"].filter(lambda example: example['lang'] in languages)\n",
    "val_dataset = dataset[\"validation\"].filter(lambda example: example['lang'] in languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300fe0ef",
   "metadata": {},
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa0bc129",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_questions =  list(train_dataset.filter(lambda x: x[\"lang\"] == \"ar\")[\"question\"])\n",
    "ko_questions = list(train_dataset.filter(lambda x: x[\"lang\"] == \"ko\")[\"question\"])\n",
    "te_questions = list(train_dataset.filter(lambda x: x[\"lang\"] == \"te\")[\"question\"])\n",
    "en_context =  list(train_dataset[\"context\"])\n",
    "\n",
    "ar_questions_val =  list(val_dataset.filter(lambda x: x[\"lang\"] == \"ar\")[\"question\"])\n",
    "ko_questions_val = list(val_dataset.filter(lambda x: x[\"lang\"] == \"ko\")[\"question\"])\n",
    "te_questions_val = list(val_dataset.filter(lambda x: x[\"lang\"] == \"te\")[\"question\"])\n",
    "en_context_val =  list(val_dataset[\"context\"])\n",
    "\n",
    "def UnfoldSentences(l):\n",
    "    return [re.findall(r'\\w+', sentence) for sentence in l]\n",
    "\n",
    "ar_questions = UnfoldSentences(ar_questions)\n",
    "ko_questions = UnfoldSentences(ko_questions)\n",
    "te_questions = UnfoldSentences(te_questions)\n",
    "en_context= UnfoldSentences(en_context)\n",
    "\n",
    "ar_questions_val = UnfoldSentences(ar_questions_val)\n",
    "ko_questions_val = UnfoldSentences(ko_questions_val)\n",
    "te_questions_val = UnfoldSentences(te_questions_val)\n",
    "en_context_val = UnfoldSentences(en_context_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a41e3a",
   "metadata": {},
   "source": [
    "## Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d887b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class UnigramModel:\n",
    "    def __init__(self, languages):\n",
    "        self.languages = languages\n",
    "        self.counters = {}\n",
    "        self.probabilities = {}\n",
    "\n",
    "        for lang in languages:\n",
    "            self.counters[lang] = Counter()\n",
    "            self.probabilities[lang] = {}\n",
    "\n",
    "    def build(self, tokenized_data):\n",
    "        # tokenize \n",
    "        for lang in self.languages:\n",
    "            sentences = tokenized_data.get(lang, [])\n",
    "            for sentence_tokens in sentences:\n",
    "                self.counters[lang].update(sentence_tokens)\n",
    "\n",
    "        # probabilities\n",
    "        for lang in self.languages:\n",
    "            total_count = sum(self.counters[lang].values())\n",
    "            for word, count in self.counters[lang].items():\n",
    "                self.probabilities[lang][word] = count / total_count\n",
    "\n",
    "    def word_probability(self, lang, word):\n",
    "        return self.probabilities.get(lang, {}).get(word, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6daf12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 probabilities for ar:\n",
      "في: 0.0366\n",
      "من: 0.0362\n",
      "متى: 0.0331\n",
      "ما: 0.0273\n",
      "هو: 0.0216\n",
      "---------------------------\n",
      "Top 5 probabilities for ko:\n",
      "가장: 0.0444\n",
      "무엇인가: 0.0419\n",
      "언제: 0.0283\n",
      "몇: 0.0197\n",
      "어디인가: 0.0192\n",
      "---------------------------\n",
      "Top 5 probabilities for te:\n",
      "ఎవరు: 0.0356\n",
      "ఏది: 0.0250\n",
      "ఎన్ని: 0.0215\n",
      "ఎప్పుడు: 0.0200\n",
      "ఏ: 0.0187\n",
      "---------------------------\n",
      "Top 5 probabilities for en:\n",
      "the: 0.0668\n",
      "of: 0.0411\n",
      "and: 0.0318\n",
      "in: 0.0266\n",
      "to: 0.0177\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = {\n",
    "    \"ar\": ar_questions,\n",
    "    \"ko\": ko_questions,\n",
    "    \"te\": te_questions,\n",
    "    \"en\": en_context\n",
    "}\n",
    "\n",
    "tokenized_val = {\n",
    "    \"ar\": ar_questions_val,\n",
    "    \"ko\": ko_questions_val,\n",
    "    \"te\": te_questions_val,\n",
    "    \"en\": en_context_val\n",
    "}\n",
    "\n",
    "unigram = UnigramModel(languages)\n",
    "unigram.build(tokenized_train)\n",
    "\n",
    "for lang in languages:\n",
    "    print(f\"Top 5 probabilities for {lang}:\")\n",
    "    probs = unigram.probabilities[lang]\n",
    "\n",
    "    top_5 = sorted(probs.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    for word, prob in top_5:\n",
    "        print(f\"{word}: {prob:.4f}\")\n",
    "        \n",
    "    print(\"---------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8deda9b",
   "metadata": {},
   "source": [
    "#### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a53d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_perplexity(model, tokenized_data, lang):\n",
    "    total_log_prob = 0\n",
    "    total_words = 0\n",
    "\n",
    "    for tokens in tokenized_data:\n",
    "        for word in tokens:\n",
    "            prob = model.word_probability(lang, word)\n",
    "            if prob == 0:\n",
    "                prob = 1e-6\n",
    "            total_log_prob += math.log2(prob)\n",
    "            total_words += 1\n",
    "\n",
    "    avg_neg_log_prob = - total_log_prob / total_words\n",
    "    perplexity = 2 ** avg_neg_log_prob\n",
    "\n",
    "    return perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "479ed189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram\n",
      "Perplexities:\n",
      "ko: 4542.269394\n",
      "ar: 3740.785237\n",
      "te: 2565.343064\n",
      "en: 2168.677714\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigram\")\n",
    "\n",
    "perplexity_ar = compute_perplexity(unigram, ar_questions_val, \"ar\")\n",
    "perplexity_ko = compute_perplexity(unigram, ko_questions_val, \"ko\")\n",
    "perplexity_te = compute_perplexity(unigram, te_questions_val, \"te\")\n",
    "perplexity_en = compute_perplexity(unigram, en_context_val, \"en\")\n",
    "\n",
    "print(\"Perplexities:\")\n",
    "print(f\"ko: {perplexity_ko:.6f}\")\n",
    "print(f\"ar: {perplexity_ar:.6f}\")\n",
    "print(f\"te: {perplexity_te:.6f}\")\n",
    "print(f\"en: {perplexity_en:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c65634d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
