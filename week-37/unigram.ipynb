{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2fa3ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"coastalcph/tydi_xor_rc\")\n",
    "languages = ['ar', 'ko', 'te']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a41e3a",
   "metadata": {},
   "source": [
    "## Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4d887b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class UnigramModel:\n",
    "    def __init__(self, languages):\n",
    "        self.languages = languages\n",
    "        self.counters = {}\n",
    "        self.probabilities = {}\n",
    "\n",
    "        for lang in languages:\n",
    "            self.counters[lang] = Counter()\n",
    "            self.probabilities[lang] = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize(text):\n",
    "        return re.findall(r'\\b\\w+\\b', text.lower())\n",
    "\n",
    "    def build(self, dataset):\n",
    "        # tokenize \n",
    "        for split in dataset.keys():\n",
    "            for lang in self.languages:\n",
    "                lang_data = dataset[split].filter(lambda x: x['lang'] == lang)\n",
    "                \n",
    "                for item in lang_data:\n",
    "                    tokens = self.tokenize(item['question'])\n",
    "                    self.counters[lang].update(tokens)\n",
    "\n",
    "        # probabilities\n",
    "        for lang in self.languages:\n",
    "            total_count = sum(self.counters[lang].values())\n",
    "            for word, count in self.counters[lang].items():\n",
    "                self.probabilities[lang][word] = count / total_count\n",
    "\n",
    "    def word_probability(self, lang, word):\n",
    "        return self.probabilities.get(lang, {}).get(word, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b6daf12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 probabilities for ar:\n",
      "من: 0.0372\n",
      "في: 0.0363\n",
      "متى: 0.0319\n",
      "ما: 0.0278\n",
      "هو: 0.0221\n",
      "---------------------------\n",
      "Top 5 probabilities for ko:\n",
      "가장: 0.0436\n",
      "무엇인가: 0.0421\n",
      "언제: 0.0279\n",
      "어디인가: 0.0189\n",
      "몇: 0.0187\n",
      "---------------------------\n",
      "Top 5 probabilities for te:\n",
      "ఎవరు: 0.0348\n",
      "ఏది: 0.0268\n",
      "ఏ: 0.0236\n",
      "ఎన్ని: 0.0191\n",
      "ఎప్పుడు: 0.0185\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "unigram = UnigramModel(languages)\n",
    "unigram.build(dataset)\n",
    "\n",
    "for lang in languages:\n",
    "    print(f\"Top 5 probabilities for {lang}:\")\n",
    "    probs = unigram.probabilities[lang]\n",
    "\n",
    "    top_5 = sorted(probs.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    for word, prob in top_5:\n",
    "        print(f\"{word}: {prob:.4f}\")\n",
    "        \n",
    "    print(\"---------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8deda9b",
   "metadata": {},
   "source": [
    "#### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4a53d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_perplexity(model, dataset, lang):\n",
    "    split_data = dataset['validation'].filter(lambda x: x['lang'] == lang)\n",
    "    total_log_prob = 0\n",
    "    total_words = 0\n",
    "\n",
    "    for item in split_data:\n",
    "        tokens = model.tokenize(item['question'])\n",
    "        for word in tokens:\n",
    "            prob = model.word_probability(lang, word)\n",
    "            if prob == 0:\n",
    "                prob = 1e-6\n",
    "            total_log_prob += math.log2(prob)\n",
    "            total_words += 1\n",
    "\n",
    "    avg_neg_log_prob = - total_log_prob / total_words\n",
    "    perplexity = 2 ** avg_neg_log_prob\n",
    "\n",
    "    return perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "479ed189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram\n",
      "Perplexity for ar: 1207.776167\n",
      "Perplexity for ko: 1100.799844\n",
      "Perplexity for te: 699.134852\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigram\")\n",
    "for lang in languages:\n",
    "    perplexity = compute_perplexity(unigram, dataset, lang)\n",
    "    print(f\"Perplexity for {lang}: {perplexity:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c65634d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
