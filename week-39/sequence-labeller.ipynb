{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c202400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since coastalcph/tydi_xor_rc couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at C:\\Users\\aarus\\.cache\\huggingface\\datasets\\coastalcph___tydi_xor_rc\\default\\0.0.0\\6c31d1c2ec1e15e57d836141bb5adb8da7df9124 (last modified on Thu Sep 25 15:11:30 2025).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert/distilbert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aarus\\AppData\\Local\\Temp\\ipykernel_31388\\211724850.py:203: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `QuestionAnsweringTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "wandb: Currently logged in as: aarushsinha60 (chungimungi) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\aarus\\Desktop\\Github\\DIKU-NLP\\week-39\\wandb\\run-20250925_153025-44jw9wlf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/chungimungi/huggingface/runs/44jw9wlf' target=\"_blank\">cosmic-waterfall-18</a></strong> to <a href='https://wandb.ai/chungimungi/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/chungimungi/huggingface' target=\"_blank\">https://wandb.ai/chungimungi/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/chungimungi/huggingface/runs/44jw9wlf' target=\"_blank\">https://wandb.ai/chungimungi/huggingface/runs/44jw9wlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='408' max='408' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [408/408 02:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating for language: ar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c7f16662d54213af8ddae773a16a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/415 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for ar: {}\n",
      "Evaluating for language: ko\n",
      "Results for ko: {}\n",
      "Evaluating for language: te\n",
      "Results for te: {}\n",
      "Training model 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aarus\\AppData\\Local\\Temp\\ipykernel_31388\\211724850.py:203: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `QuestionAnsweringTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='408' max='408' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [408/408 02:30, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating for language: ar\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for ar: {}\n",
      "Evaluating for language: ko\n",
      "Results for ko: {}\n",
      "Evaluating for language: te\n",
      "Results for te: {}\n",
      "Training model 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aarus\\AppData\\Local\\Temp\\ipykernel_31388\\211724850.py:203: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `QuestionAnsweringTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='408' max='408' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [408/408 02:30, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating for language: ar\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for ar: {}\n",
      "Evaluating for language: ko\n",
      "Results for ko: {}\n",
      "Evaluating for language: te\n",
      "Results for te: {}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "\n",
    "k = 3\n",
    "model_checkpoint = \"distilbert/distilbert-base-multilingual-cased\"\n",
    "batch_size = 16\n",
    "max_length = 384\n",
    "doc_stride = 128\n",
    "languages = ['ar', 'ko', 'te']\n",
    "\n",
    "dataset = load_dataset(\"coastalcph/tydi_xor_rc\")\n",
    "\n",
    "def add_example_id(example, idx):\n",
    "    example[\"id\"] = str(idx)\n",
    "    return example\n",
    "\n",
    "def format_answer(example):\n",
    "    if isinstance(example[\"answer\"], str) and example[\"answer\"].strip().startswith(\"{\"):\n",
    "        try:\n",
    "            ans_dict = json.loads(example[\"answer\"])\n",
    "            example[\"answer_start\"] = ans_dict.get(\"answer_start\", [-1])[0] if ans_dict.get(\"answer_start\") else -1\n",
    "            example[\"answer\"] = ans_dict.get(\"text\", [\"\"])[0]\n",
    "        except json.JSONDecodeError:\n",
    "            example[\"answer_start\"] = -1\n",
    "            example[\"answer\"] = \"\"\n",
    "    elif isinstance(example[\"answer\"], dict):\n",
    "        example[\"answer_start\"] = example[\"answer\"].get(\"answer_start\", [-1])[0]\n",
    "        example[\"answer\"] = example[\"answer\"].get(\"text\", [\"\"])[0]\n",
    "    return example\n",
    "\n",
    "train_dataset = dataset[\"train\"].filter(lambda example: example['lang'] in languages).map(add_example_id, with_indices=True).map(format_answer)\n",
    "val_dataset = dataset[\"validation\"].filter(lambda example: example['lang'] in languages).map(add_example_id, with_indices=True).map(format_answer)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "\n",
    "def prepare_train_features(examples):\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        sample_index = sample_mapping[i]\n",
    "        \n",
    "        answer_start = examples[\"answer_start\"][sample_index]\n",
    "        answer_text = examples[\"answer\"][sample_index]\n",
    "\n",
    "        if answer_start == -1:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            start_char = answer_start\n",
    "            end_char = start_char + len(answer_text)\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "    return tokenized_examples\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(prepare_train_features, batched=True, remove_columns=train_dataset.column_names)\n",
    "\n",
    "def prepare_validation_features(examples):\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "    return tokenized_examples\n",
    "\n",
    "tokenized_val_dataset = val_dataset.map(prepare_validation_features, batched=True, remove_columns=val_dataset.column_names)\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"finetuned-qa\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size=20, max_answer_length=30):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "    predictions = collections.OrderedDict()\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        feature_indices = features_per_example[example_index]\n",
    "        min_null_score = None\n",
    "        valid_answers = []\n",
    "        context = example[\"context\"]\n",
    "        for feature_index in feature_indices:\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char:end_char],\n",
    "                        }\n",
    "                    )\n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "        \n",
    "        predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "metric = evaluate.load(\"squad\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(predictions=p.predictions, references=p.label)\n",
    "\n",
    "def post_processing_function(examples, features, predictions, stage=\"eval\"):\n",
    "    predictions = postprocess_qa_predictions(examples=examples, features=features, raw_predictions=predictions)\n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in predictions.items()]\n",
    "    references = [{\"id\": ex[\"id\"], \"answers\": {\"text\": [ex[\"answer\"]], \"answer_start\": [ex[\"answer_start\"]]}} for ex in examples]\n",
    "    return metric.compute(predictions=formatted_predictions, references=references)\n",
    "\n",
    "class QuestionAnsweringTrainer(Trainer):\n",
    "    def __init__(self, *args, eval_examples=None, post_process_function=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.eval_examples = eval_examples\n",
    "        self.post_process_function = post_process_function\n",
    "\n",
    "    def evaluate(self, eval_dataset=None, eval_examples=None, ignore_keys=None, metric_key_prefix: str = \"eval\"):\n",
    "        eval_dataset = self.eval_dataset if eval_dataset is None else eval_dataset\n",
    "        eval_dataloader = self.get_eval_dataloader(eval_dataset)\n",
    "        eval_examples = self.eval_examples if eval_examples is None else eval_examples\n",
    "\n",
    "        compute_metrics = self.compute_metrics\n",
    "        self.compute_metrics = None\n",
    "        eval_loop = self.prediction_loop if self.args.use_legacy_prediction_loop else self.evaluation_loop\n",
    "        try:\n",
    "            output = eval_loop(\n",
    "                eval_dataloader,\n",
    "                description=\"Evaluation\",\n",
    "                prediction_loss_only=True if compute_metrics is None else None,\n",
    "                ignore_keys=ignore_keys,\n",
    "            )\n",
    "        finally:\n",
    "            self.compute_metrics = compute_metrics\n",
    "\n",
    "        if self.post_process_function is not None and self.compute_metrics is not None:\n",
    "            eval_preds = self.post_process_function(eval_examples, eval_dataset, output.predictions)\n",
    "            metrics = {**eval_preds}\n",
    "            self.log(metrics)\n",
    "        else:\n",
    "            metrics = {}\n",
    "\n",
    "        self.control = self.callback_handler.on_evaluate(self.args, self.state, self.control, metrics)\n",
    "        return metrics\n",
    "\n",
    "for i in range(k):\n",
    "    print(f\"Training model {i+1}/{k}\")\n",
    "    trainer = QuestionAnsweringTrainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=tokenized_train_dataset,\n",
    "        eval_dataset=tokenized_val_dataset,\n",
    "        eval_examples=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        post_process_function=post_processing_function,\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    for lang in languages:\n",
    "        print(f\"Evaluating for language: {lang}\")\n",
    "        lang_val_dataset = val_dataset.filter(lambda example: example['lang'] == lang)\n",
    "        lang_tokenized_val_dataset = lang_val_dataset.map(prepare_validation_features, batched=True, remove_columns=val_dataset.column_names)\n",
    "        \n",
    "        metrics = trainer.evaluate(eval_dataset=lang_tokenized_val_dataset, eval_examples=lang_val_dataset)\n",
    "        print(f\"Results for {lang}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c7be826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training token-classifier for language: ar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\aarus\\AppData\\Local\\Temp\\ipykernel_31388\\3895613878.py:101: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_tc = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='334' max='334' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [334/334 01:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.101309</td>\n",
       "      <td>0.598485</td>\n",
       "      <td>0.045559</td>\n",
       "      <td>0.084673</td>\n",
       "      <td>0.972713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [55/55 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for ar: {'eval_loss': 0.10130859166383743, 'eval_precision': 0.5984848484848485, 'eval_recall': 0.04555940023068051, 'eval_f1': 0.08467309753483387, 'eval_accuracy': 0.972712603645775, 'eval_runtime': 2.9675, 'eval_samples_per_second': 146.926, 'eval_steps_per_second': 18.534, 'epoch': 1.0}\n",
      "Training token-classifier for language: ko\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b0ee9c9caa4c4e9544c4b5f845b249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/6335 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69bd141b2494f108d6011b4c897bfde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0399e53bd0b44528ef1785023356fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2422 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0d2272de97461f8c6d838ec63ce499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/356 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\aarus\\AppData\\Local\\Temp\\ipykernel_31388\\3895613878.py:101: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_tc = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='310' max='310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [310/310 01:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.090100</td>\n",
       "      <td>0.113132</td>\n",
       "      <td>0.630662</td>\n",
       "      <td>0.111453</td>\n",
       "      <td>0.189430</td>\n",
       "      <td>0.967272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for ko: {'eval_loss': 0.11313216388225555, 'eval_precision': 0.6306620209059234, 'eval_recall': 0.11145320197044335, 'eval_f1': 0.18942961800104657, 'eval_accuracy': 0.9672723431227551, 'eval_runtime': 2.3927, 'eval_samples_per_second': 151.295, 'eval_steps_per_second': 19.225, 'epoch': 1.0}\n",
      "Training token-classifier for language: te\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b6c794dd8b400eb51eff9fb6f42fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/6335 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f33888bbe73410dbe3ada5c45abe34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b604a1909d4abea59e517de30a80ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109dfab743394edf87c9b25d7e824f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/384 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\aarus\\AppData\\Local\\Temp\\ipykernel_31388\\3895613878.py:101: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_tc = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='172' max='172' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [172/172 00:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.118100</td>\n",
       "      <td>0.078299</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.015831</td>\n",
       "      <td>0.030717</td>\n",
       "      <td>0.980213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for te: {'eval_loss': 0.07829934358596802, 'eval_precision': 0.5142857142857142, 'eval_recall': 0.0158311345646438, 'eval_f1': 0.030716723549488054, 'eval_accuracy': 0.9802125065319631, 'eval_runtime': 2.5508, 'eval_samples_per_second': 152.108, 'eval_steps_per_second': 19.209, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ar': {'eval_loss': 0.10130859166383743,\n",
       "  'eval_precision': 0.5984848484848485,\n",
       "  'eval_recall': 0.04555940023068051,\n",
       "  'eval_f1': 0.08467309753483387,\n",
       "  'eval_accuracy': 0.972712603645775,\n",
       "  'eval_runtime': 2.9675,\n",
       "  'eval_samples_per_second': 146.926,\n",
       "  'eval_steps_per_second': 18.534,\n",
       "  'epoch': 1.0},\n",
       " 'ko': {'eval_loss': 0.11313216388225555,\n",
       "  'eval_precision': 0.6306620209059234,\n",
       "  'eval_recall': 0.11145320197044335,\n",
       "  'eval_f1': 0.18942961800104657,\n",
       "  'eval_accuracy': 0.9672723431227551,\n",
       "  'eval_runtime': 2.3927,\n",
       "  'eval_samples_per_second': 151.295,\n",
       "  'eval_steps_per_second': 19.225,\n",
       "  'epoch': 1.0},\n",
       " 'te': {'eval_loss': 0.07829934358596802,\n",
       "  'eval_precision': 0.5142857142857142,\n",
       "  'eval_recall': 0.0158311345646438,\n",
       "  'eval_f1': 0.030716723549488054,\n",
       "  'eval_accuracy': 0.9802125065319631,\n",
       "  'eval_runtime': 2.5508,\n",
       "  'eval_samples_per_second': 152.108,\n",
       "  'eval_steps_per_second': 19.209,\n",
       "  'epoch': 1.0}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "label_list = [\"O\", \"ANS\"]\n",
    "label_to_id = {l: i for i, l in enumerate(label_list)}\n",
    "id_to_label = {i: l for l, i in label_to_id.items()}\n",
    "\n",
    "max_length = 384\n",
    "doc_stride = 128\n",
    "\n",
    "\n",
    "def create_token_labels(examples):\n",
    "    # Build token-level labels for the context part only; question tokens get label -100\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_mapping = tokenized.pop(\"overflow_to_sample_mapping\")\n",
    "    offsets_mapping = tokenized.pop(\"offset_mapping\")\n",
    "\n",
    "    labels = []\n",
    "    for i, offsets in enumerate(offsets_mapping):\n",
    "        sequence_ids = tokenized.sequence_ids(i)\n",
    "        sample_idx = sample_mapping[i]\n",
    "        answer_start = examples[\"answer_start\"][sample_idx]\n",
    "        answer_text = examples[\"answer\"][sample_idx]\n",
    "        answer_end = -1 if answer_start == -1 else answer_start + len(answer_text)\n",
    "\n",
    "        example_labels = []\n",
    "        context_id = 1 if pad_on_right else 0\n",
    "        for idx, offset in enumerate(offsets):\n",
    "            if sequence_ids[idx] is None:\n",
    "                example_labels.append(-100)\n",
    "            elif sequence_ids[idx] != context_id:\n",
    "                example_labels.append(-100)\n",
    "            else:\n",
    "                if answer_start == -1 or offset is None:\n",
    "                    example_labels.append(label_to_id[\"O\"])  # unanswerable â†’ no tokens\n",
    "                else:\n",
    "                    start, end = offset\n",
    "                    if start >= answer_end or end <= answer_start:\n",
    "                        example_labels.append(label_to_id[\"O\"])  # outside answer span\n",
    "                    else:\n",
    "                        example_labels.append(label_to_id[\"ANS\"])  # overlaps answer span\n",
    "        labels.append(example_labels)\n",
    "\n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "def compute_token_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    # Only evaluate on context tokens (labels != -100)\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    for p, l in zip(preds, labels):\n",
    "        for pi, li in zip(p, l):\n",
    "            if li != -100:\n",
    "                true_labels.append(li)\n",
    "                pred_labels.append(pi)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, labels=[label_to_id[\"ANS\"]], average=\"binary\")\n",
    "    acc = accuracy_score(true_labels, pred_labels)\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": acc}\n",
    "\n",
    "\n",
    "results_by_lang = {}\n",
    "for lang in languages:\n",
    "    print(f\"Training token-classifier for language: {lang}\")\n",
    "    lang_train = train_dataset.filter(lambda ex: ex[\"lang\"] == lang)\n",
    "    lang_val = val_dataset.filter(lambda ex: ex[\"lang\"] == lang)\n",
    "\n",
    "    tokenized_lang_train = lang_train.map(create_token_labels, batched=True, remove_columns=lang_train.column_names)\n",
    "    tokenized_lang_val = lang_val.map(create_token_labels, batched=True, remove_columns=lang_val.column_names)\n",
    "\n",
    "    model_tc = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list), id2label=id_to_label, label2id=label_to_id)\n",
    "    args_tc = TrainingArguments(\n",
    "        output_dir=f\"seq-lab-{lang}\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        learning_rate=3e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=50,\n",
    "        save_strategy=\"no\",\n",
    "        report_to=[],\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "    trainer_tc = Trainer(\n",
    "        model=model_tc,\n",
    "        args=args_tc,\n",
    "        train_dataset=tokenized_lang_train,\n",
    "        eval_dataset=tokenized_lang_val,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_token_metrics,\n",
    "    )\n",
    "\n",
    "    trainer_tc.train()\n",
    "    metrics = trainer_tc.evaluate()\n",
    "    results_by_lang[lang] = metrics\n",
    "    print(f\"Results for {lang}: {metrics}\")\n",
    "\n",
    "results_by_lang\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
