{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "250e88b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: AR\n",
      "\n",
      "--- Class Distribution for AR_TRAIN ---\n",
      "Class 0 (Not Answerable): 255 (9.97%)\n",
      "Class 1 (Answerable): 2303 (90.03%)\n",
      "Imbalance Ratio: 9.03:1\n",
      "\n",
      "--- Class Distribution for AR_VALIDATION ---\n",
      "Class 0 (Not Answerable): 52 (12.53%)\n",
      "Class 1 (Answerable): 363 (87.47%)\n",
      "Imbalance Ratio: 6.98:1\n",
      "Computed class weights: {0: 5.015686274509804, 1: 0.5553625705601389}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Zero-Shot Evaluation for AR...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot results: Acc=0.3807, F1=0.4990, Precision=0.8533, Recall=0.3526\n",
      "\n",
      "Fine-Tuning Model with Class Balancing for AR...\n",
      "Moderate imbalance detected (ratio: 9.03:1). Using Class Weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='960' max='960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [960/960 04:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>0.148033</td>\n",
       "      <td>0.980723</td>\n",
       "      <td>0.988920</td>\n",
       "      <td>0.994429</td>\n",
       "      <td>0.983471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.149400</td>\n",
       "      <td>0.150443</td>\n",
       "      <td>0.980723</td>\n",
       "      <td>0.988920</td>\n",
       "      <td>0.994429</td>\n",
       "      <td>0.983471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.149198</td>\n",
       "      <td>0.980723</td>\n",
       "      <td>0.988920</td>\n",
       "      <td>0.994429</td>\n",
       "      <td>0.983471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Fine-Tuned Model for AR...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned results: Acc=0.9807, F1=0.9889, Precision=0.9944, Recall=0.9835\n",
      "Language: KO\n",
      "\n",
      "--- Class Distribution for KO_TRAIN ---\n",
      "Class 0 (Not Answerable): 63 (2.60%)\n",
      "Class 1 (Answerable): 2359 (97.40%)\n",
      "Imbalance Ratio: 37.44:1\n",
      "\n",
      "--- Class Distribution for KO_VALIDATION ---\n",
      "Class 0 (Not Answerable): 19 (5.34%)\n",
      "Class 1 (Answerable): 337 (94.66%)\n",
      "Imbalance Ratio: 17.74:1\n",
      "Computed class weights: {0: 19.22222222222222, 1: 0.5133531157270029}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f214067e7344c3ac7aad39684a5bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2422 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Zero-Shot Evaluation for KO...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot results: Acc=0.0646, F1=0.0235, Precision=1.0000, Recall=0.0119\n",
      "\n",
      "Fine-Tuning Model with Class Balancing for KO...\n",
      "Severe imbalance detected (ratio: 37.44:1). Using Focal Loss.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='909' max='909' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [909/909 04:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.014385</td>\n",
       "      <td>0.946629</td>\n",
       "      <td>0.972583</td>\n",
       "      <td>0.946629</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.013551</td>\n",
       "      <td>0.946629</td>\n",
       "      <td>0.972583</td>\n",
       "      <td>0.946629</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.013622</td>\n",
       "      <td>0.949438</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>0.951841</td>\n",
       "      <td>0.997033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Fine-Tuned Model for KO...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned results: Acc=0.9494, F1=0.9739, Precision=0.9518, Recall=0.9970\n",
      "Language: TE\n",
      "\n",
      "--- Class Distribution for TE_TRAIN ---\n",
      "Class 0 (Not Answerable): 45 (3.32%)\n",
      "Class 1 (Answerable): 1310 (96.68%)\n",
      "Imbalance Ratio: 29.11:1\n",
      "\n",
      "--- Class Distribution for TE_VALIDATION ---\n",
      "Class 0 (Not Answerable): 93 (24.22%)\n",
      "Class 1 (Answerable): 291 (75.78%)\n",
      "Imbalance Ratio: 3.13:1\n",
      "Computed class weights: {0: 15.055555555555555, 1: 0.517175572519084}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Zero-Shot Evaluation for TE...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot results: Acc=0.2422, F1=0.0136, Precision=0.5000, Recall=0.0069\n",
      "\n",
      "Fine-Tuning Model with Class Balancing for TE...\n",
      "Severe imbalance detected (ratio: 29.11:1). Using Focal Loss.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='510' max='510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [510/510 02:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.028354</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.934853</td>\n",
       "      <td>0.888545</td>\n",
       "      <td>0.986254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.027777</td>\n",
       "      <td>0.911458</td>\n",
       "      <td>0.944079</td>\n",
       "      <td>0.905363</td>\n",
       "      <td>0.986254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.028787</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.955075</td>\n",
       "      <td>0.925806</td>\n",
       "      <td>0.986254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Fine-Tuned Model for TE...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned results: Acc=0.9297, F1=0.9551, Precision=0.9258, Recall=0.9863\n",
      "\n",
      "Language: AR\n",
      "----------------------------------------\n",
      "Training Set - Class 0: 255, Class 1: 2303\n",
      "Imbalance Ratio: 9.03:1\n",
      "\n",
      "Zero-Shot Performance:\n",
      "  Accuracy: 0.3807\n",
      "  F1: 0.4990\n",
      "  Precision: 0.8533\n",
      "  Recall: 0.3526\n",
      "\n",
      "Fine-Tuned Performance (Balanced):\n",
      "  Accuracy: 0.9807\n",
      "  F1: 0.9889\n",
      "  Precision: 0.9944\n",
      "  Recall: 0.9835\n",
      "\n",
      "Improvements:\n",
      "  Accuracy: +0.6000\n",
      "  F1: +0.4899\n",
      "  Precision: +0.1411\n",
      "  Recall: +0.6309\n",
      "\n",
      "Language: KO\n",
      "----------------------------------------\n",
      "Training Set - Class 0: 63, Class 1: 2359\n",
      "Imbalance Ratio: 37.44:1\n",
      "\n",
      "Zero-Shot Performance:\n",
      "  Accuracy: 0.0646\n",
      "  F1: 0.0235\n",
      "  Precision: 1.0000\n",
      "  Recall: 0.0119\n",
      "\n",
      "Fine-Tuned Performance (Balanced):\n",
      "  Accuracy: 0.9494\n",
      "  F1: 0.9739\n",
      "  Precision: 0.9518\n",
      "  Recall: 0.9970\n",
      "\n",
      "Improvements:\n",
      "  Accuracy: +0.8848\n",
      "  F1: +0.9505\n",
      "  Precision: -0.0482\n",
      "  Recall: +0.9852\n",
      "\n",
      "Language: TE\n",
      "----------------------------------------\n",
      "Training Set - Class 0: 45, Class 1: 1310\n",
      "Imbalance Ratio: 29.11:1\n",
      "\n",
      "Zero-Shot Performance:\n",
      "  Accuracy: 0.2422\n",
      "  F1: 0.0136\n",
      "  Precision: 0.5000\n",
      "  Recall: 0.0069\n",
      "\n",
      "Fine-Tuned Performance (Balanced):\n",
      "  Accuracy: 0.9297\n",
      "  F1: 0.9551\n",
      "  Precision: 0.9258\n",
      "  Recall: 0.9863\n",
      "\n",
      "Improvements:\n",
      "  Accuracy: +0.6875\n",
      "  F1: +0.9415\n",
      "  Precision: +0.4258\n",
      "  Recall: +0.9794\n",
      "SUMMARY STATISTICS\n",
      "Average Improvements Across Languages:\n",
      "  Accuracy: +0.7241\n",
      "  F1: +0.7940\n",
      "  Precision: +0.1729\n",
      "  Recall: +0.8651\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "full_dataset = load_dataset(\"coastalcph/tydi_xor_rc\")\n",
    "\n",
    "model_checkpoint = \"distilbert/distilbert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    tokenized_input = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=512,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    tokenized_input[\"label\"] = [int(ans) for ans in examples[\"answerable\"]]\n",
    "    return tokenized_input\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "def analyze_class_distribution(dataset, lang):\n",
    "    labels = [int(example['answerable']) for example in dataset]\n",
    "    counter = Counter(labels)\n",
    "    total = len(labels)\n",
    "    \n",
    "    print(f\"\\n--- Class Distribution for {lang.upper()} ---\")\n",
    "    print(f\"Class 0 (Not Answerable): {counter[0]} ({counter[0]/total:.2%})\")\n",
    "    print(f\"Class 1 (Answerable): {counter[1]} ({counter[1]/total:.2%})\")\n",
    "    print(f\"Imbalance Ratio: {max(counter.values()) / min(counter.values()):.2f}:1\")\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def compute_class_weights(labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    class_weights = compute_class_weight('balanced', classes=unique_labels, y=labels)\n",
    "    class_weight_dict = dict(zip(unique_labels, class_weights))\n",
    "    \n",
    "    print(f\"Computed class weights: {class_weight_dict}\")\n",
    "    return torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "class WeightedTrainer(Trainer):    \n",
    "    def __init__(self, class_weights=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.class_weights = class_weights\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        \n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        \n",
    "        if self.class_weights is not None:\n",
    "            weights = self.class_weights.to(logits.device)\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
    "        else:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            \n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def apply_focal_loss_trainer(alpha=0.25, gamma=2.0):\n",
    "    \n",
    "    class FocalLossTrainer(Trainer):\n",
    "        def __init__(self, alpha=alpha, gamma=gamma, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.alpha = alpha\n",
    "            self.gamma = gamma\n",
    "            \n",
    "        def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "\n",
    "            labels = inputs.get(\"labels\")\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.get('logits')\n",
    "            \n",
    "            ce_loss = nn.CrossEntropyLoss(reduction='none')(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "            pt = torch.exp(-ce_loss)\n",
    "            focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "            loss = focal_loss.mean()\n",
    "            \n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "    return FocalLossTrainer\n",
    "\n",
    "languages = ['ar', 'ko', 'te']\n",
    "results = {}\n",
    "\n",
    "for lang in languages:\n",
    "    print(f\"Language: {lang.upper()}\")\n",
    "    \n",
    "    train_dataset = full_dataset[\"train\"].filter(lambda example: example['lang'] == lang)\n",
    "    val_dataset = full_dataset[\"validation\"].filter(lambda example: example['lang'] == lang)\n",
    "\n",
    "    train_labels = analyze_class_distribution(train_dataset, f\"{lang}_train\")\n",
    "    val_labels = analyze_class_distribution(val_dataset, f\"{lang}_validation\")\n",
    "    \n",
    "    class_weights = compute_class_weights(train_labels)\n",
    "    \n",
    "    tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
    "    tokenized_val = val_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\n",
    "\n",
    "    print(f\"\\nPerforming Zero-Shot Evaluation for {lang.upper()}...\")\n",
    "    \n",
    "    zero_shot_trainer = Trainer(\n",
    "        model=model,\n",
    "        eval_dataset=tokenized_val,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    zero_shot_results = zero_shot_trainer.evaluate()\n",
    "    \n",
    "    print(f\"Zero-shot results: Acc={zero_shot_results['eval_accuracy']:.4f}, \"\n",
    "          f\"F1={zero_shot_results['eval_f1']:.4f}, \"\n",
    "          f\"Precision={zero_shot_results['eval_precision']:.4f}, \"\n",
    "          f\"Recall={zero_shot_results['eval_recall']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nFine-Tuning Model with Class Balancing for {lang.upper()}...\")\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results_{lang}\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        eval_steps=50,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=3,  \n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f'./logs_{lang}',\n",
    "        logging_steps=50,\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_f1\",  \n",
    "        greater_is_better=True,\n",
    "        save_total_limit=2,\n",
    "        dataloader_pin_memory=False, \n",
    "    )\n",
    "\n",
    "    imbalance_ratio = max(Counter(train_labels).values()) / min(Counter(train_labels).values())\n",
    "    \n",
    "    if imbalance_ratio > 10:  \n",
    "        print(f\"Severe imbalance detected (ratio: {imbalance_ratio:.2f}:1). Using Focal Loss.\")\n",
    "        TrainerClass = apply_focal_loss_trainer(alpha=0.25, gamma=2.0)\n",
    "        trainer = TrainerClass(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_val,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "    else:  \n",
    "        print(f\"Moderate imbalance detected (ratio: {imbalance_ratio:.2f}:1). Using Class Weights.\")\n",
    "        trainer = WeightedTrainer(\n",
    "            class_weights=class_weights,\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_val,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    print(f\"\\nEvaluating Fine-Tuned Model for {lang.upper()}...\")\n",
    "    final_eval_results = trainer.evaluate()\n",
    "    \n",
    "    print(f\"Fine-tuned results: Acc={final_eval_results['eval_accuracy']:.4f}, \"\n",
    "          f\"F1={final_eval_results['eval_f1']:.4f}, \"\n",
    "          f\"Precision={final_eval_results['eval_precision']:.4f}, \"\n",
    "          f\"Recall={final_eval_results['eval_recall']:.4f}\")\n",
    "    \n",
    "    results[lang] = {\n",
    "        \"zero_shot\": zero_shot_results,\n",
    "        \"fine_tuned\": final_eval_results,\n",
    "        \"class_distribution\": {\n",
    "            \"train\": dict(Counter(train_labels)),\n",
    "            \"val\": dict(Counter(val_labels))\n",
    "        },\n",
    "        \"imbalance_ratio\": imbalance_ratio\n",
    "    }\n",
    "\n",
    "for lang, res in results.items():\n",
    "    print(f\"\\nLanguage: {lang.upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    train_dist = res['class_distribution']['train']\n",
    "    print(f\"Training Set - Class 0: {train_dist.get(0, 0)}, Class 1: {train_dist.get(1, 0)}\")\n",
    "    print(f\"Imbalance Ratio: {res['imbalance_ratio']:.2f}:1\")\n",
    "    \n",
    "    zs_metrics = res['zero_shot']\n",
    "    ft_metrics = res['fine_tuned']\n",
    "    \n",
    "    print(f\"\\nZero-Shot Performance:\")\n",
    "    print(f\"  Accuracy: {zs_metrics['eval_accuracy']:.4f}\")\n",
    "    print(f\"  F1: {zs_metrics['eval_f1']:.4f}\")\n",
    "    print(f\"  Precision: {zs_metrics['eval_precision']:.4f}\")\n",
    "    print(f\"  Recall: {zs_metrics['eval_recall']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nFine-Tuned Performance (Balanced):\")\n",
    "    print(f\"  Accuracy: {ft_metrics['eval_accuracy']:.4f}\")\n",
    "    print(f\"  F1: {ft_metrics['eval_f1']:.4f}\")\n",
    "    print(f\"  Precision: {ft_metrics['eval_precision']:.4f}\")\n",
    "    print(f\"  Recall: {ft_metrics['eval_recall']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nImprovements:\")\n",
    "    print(f\"  Accuracy: {ft_metrics['eval_accuracy'] - zs_metrics['eval_accuracy']:+.4f}\")\n",
    "    print(f\"  F1: {ft_metrics['eval_f1'] - zs_metrics['eval_f1']:+.4f}\")\n",
    "    print(f\"  Precision: {ft_metrics['eval_precision'] - zs_metrics['eval_precision']:+.4f}\")\n",
    "    print(f\"  Recall: {ft_metrics['eval_recall'] - zs_metrics['eval_recall']:+.4f}\")\n",
    "\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "\n",
    "avg_improvements = {\n",
    "    'accuracy': np.mean([res['fine_tuned']['eval_accuracy'] - res['zero_shot']['eval_accuracy'] for res in results.values()]),\n",
    "    'f1': np.mean([res['fine_tuned']['eval_f1'] - res['zero_shot']['eval_f1'] for res in results.values()]),\n",
    "    'precision': np.mean([res['fine_tuned']['eval_precision'] - res['zero_shot']['eval_precision'] for res in results.values()]),\n",
    "    'recall': np.mean([res['fine_tuned']['eval_recall'] - res['zero_shot']['eval_recall'] for res in results.values()])\n",
    "}\n",
    "\n",
    "print(f\"Average Improvements Across Languages:\")\n",
    "for metric, improvement in avg_improvements.items():\n",
    "    print(f\"  {metric.capitalize()}: {improvement:+.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
