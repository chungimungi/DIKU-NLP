{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f925dfd2",
   "metadata": {},
   "source": [
    "## 3 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250e88b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: AR\n",
      "\n",
      "--- Class Distribution for AR_TRAIN ---\n",
      "Class 0 (Not Answerable): 255 (9.97%)\n",
      "Class 1 (Answerable): 2303 (90.03%)\n",
      "Imbalance Ratio: 9.03:1\n",
      "\n",
      "--- Class Distribution for AR_VALIDATION ---\n",
      "Class 0 (Not Answerable): 52 (12.53%)\n",
      "Class 1 (Answerable): 363 (87.47%)\n",
      "Imbalance Ratio: 6.98:1\n",
      "Computed class weights: {0: 5.015686274509804, 1: 0.5553625705601389}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be7c9a9a4f449a49af59adc6890358e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/415 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Zero-Shot Evaluation for AR...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: aarushsinha60 (chungimungi) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\aarus\\Desktop\\Github\\DIKU-NLP\\week-38\\wandb\\run-20251005_224615-z5hfoc6y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/chungimungi/huggingface/runs/z5hfoc6y' target=\"_blank\">vital-bird-20</a></strong> to <a href='https://wandb.ai/chungimungi/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/chungimungi/huggingface' target=\"_blank\">https://wandb.ai/chungimungi/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/chungimungi/huggingface/runs/z5hfoc6y' target=\"_blank\">https://wandb.ai/chungimungi/huggingface/runs/z5hfoc6y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot results: Acc=0.8747, F1=0.9332, Precision=0.8747, Recall=1.0000\n",
      "\n",
      "Fine-Tuning Model with Class Balancing for AR...\n",
      "Moderate imbalance detected (ratio: 9.03:1). Using Class Weights.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='960' max='960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [960/960 04:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.258700</td>\n",
       "      <td>0.146387</td>\n",
       "      <td>0.980723</td>\n",
       "      <td>0.988920</td>\n",
       "      <td>0.994429</td>\n",
       "      <td>0.983471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.150200</td>\n",
       "      <td>0.140106</td>\n",
       "      <td>0.980723</td>\n",
       "      <td>0.988920</td>\n",
       "      <td>0.994429</td>\n",
       "      <td>0.983471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.120200</td>\n",
       "      <td>0.144614</td>\n",
       "      <td>0.980723</td>\n",
       "      <td>0.988920</td>\n",
       "      <td>0.994429</td>\n",
       "      <td>0.983471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Fine-Tuned Model for AR...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned results: Acc=0.9807, F1=0.9889, Precision=0.9944, Recall=0.9835\n",
      "Model for AR saved to ./models/ar_fine_tuned\n",
      "Language: KO\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eab280a460849c980f3f61762f469a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/15343 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1808fde1c44d4bb5eb78c6ade84eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3011 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Class Distribution for KO_TRAIN ---\n",
      "Class 0 (Not Answerable): 63 (2.60%)\n",
      "Class 1 (Answerable): 2359 (97.40%)\n",
      "Imbalance Ratio: 37.44:1\n",
      "\n",
      "--- Class Distribution for KO_VALIDATION ---\n",
      "Class 0 (Not Answerable): 19 (5.34%)\n",
      "Class 1 (Answerable): 337 (94.66%)\n",
      "Imbalance Ratio: 17.74:1\n",
      "Computed class weights: {0: 19.22222222222222, 1: 0.5133531157270029}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c8816b232549179be900cf5b53f805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2422 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8015396afce9412284ff30672b1dfa32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/356 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Zero-Shot Evaluation for KO...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot results: Acc=0.0646, F1=0.0235, Precision=1.0000, Recall=0.0119\n",
      "\n",
      "Fine-Tuning Model with Class Balancing for KO...\n",
      "Severe imbalance detected (ratio: 37.44:1). Using Focal Loss.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='909' max='909' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [909/909 04:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.014385</td>\n",
       "      <td>0.946629</td>\n",
       "      <td>0.972583</td>\n",
       "      <td>0.946629</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.013551</td>\n",
       "      <td>0.946629</td>\n",
       "      <td>0.972583</td>\n",
       "      <td>0.946629</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.013622</td>\n",
       "      <td>0.949438</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>0.951841</td>\n",
       "      <td>0.997033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Fine-Tuned Model for KO...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned results: Acc=0.9494, F1=0.9739, Precision=0.9518, Recall=0.9970\n",
      "Model for KO saved to ./models/ko_fine_tuned\n",
      "Language: TE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd3a04cd20b4c32973d5847ca2f7060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/15343 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f670b5a15d9a4a33a808365d26927a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3011 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Class Distribution for TE_TRAIN ---\n",
      "Class 0 (Not Answerable): 45 (3.32%)\n",
      "Class 1 (Answerable): 1310 (96.68%)\n",
      "Imbalance Ratio: 29.11:1\n",
      "\n",
      "--- Class Distribution for TE_VALIDATION ---\n",
      "Class 0 (Not Answerable): 93 (24.22%)\n",
      "Class 1 (Answerable): 291 (75.78%)\n",
      "Imbalance Ratio: 3.13:1\n",
      "Computed class weights: {0: 15.055555555555555, 1: 0.517175572519084}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b50af974b9e4b518e7c7f121f6e4051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b87797129d4a659f1fad5978501633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/384 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Zero-Shot Evaluation for TE...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot results: Acc=0.2422, F1=0.0136, Precision=0.5000, Recall=0.0069\n",
      "\n",
      "Fine-Tuning Model with Class Balancing for TE...\n",
      "Severe imbalance detected (ratio: 29.11:1). Using Focal Loss.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='510' max='510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [510/510 02:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.028354</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.934853</td>\n",
       "      <td>0.888545</td>\n",
       "      <td>0.986254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.027777</td>\n",
       "      <td>0.911458</td>\n",
       "      <td>0.944079</td>\n",
       "      <td>0.905363</td>\n",
       "      <td>0.986254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.028787</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.955075</td>\n",
       "      <td>0.925806</td>\n",
       "      <td>0.986254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Fine-Tuned Model for TE...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned results: Acc=0.9297, F1=0.9551, Precision=0.9258, Recall=0.9863\n",
      "Model for TE saved to ./models/te_fine_tuned\n",
      "\n",
      "Language: AR\n",
      "----------------------------------------\n",
      "Training Set - Class 0: 255, Class 1: 2303\n",
      "Imbalance Ratio: 9.03:1\n",
      "\n",
      "Zero-Shot Performance:\n",
      "  Accuracy: 0.8747\n",
      "  F1: 0.9332\n",
      "  Precision: 0.8747\n",
      "  Recall: 1.0000\n",
      "\n",
      "Fine-Tuned Performance (Balanced):\n",
      "  Accuracy: 0.9807\n",
      "  F1: 0.9889\n",
      "  Precision: 0.9944\n",
      "  Recall: 0.9835\n",
      "\n",
      "Improvements:\n",
      "  Accuracy: +0.1060\n",
      "  F1: +0.0558\n",
      "  Precision: +0.1197\n",
      "  Recall: -0.0165\n",
      "\n",
      "Language: KO\n",
      "----------------------------------------\n",
      "Training Set - Class 0: 63, Class 1: 2359\n",
      "Imbalance Ratio: 37.44:1\n",
      "\n",
      "Zero-Shot Performance:\n",
      "  Accuracy: 0.0646\n",
      "  F1: 0.0235\n",
      "  Precision: 1.0000\n",
      "  Recall: 0.0119\n",
      "\n",
      "Fine-Tuned Performance (Balanced):\n",
      "  Accuracy: 0.9494\n",
      "  F1: 0.9739\n",
      "  Precision: 0.9518\n",
      "  Recall: 0.9970\n",
      "\n",
      "Improvements:\n",
      "  Accuracy: +0.8848\n",
      "  F1: +0.9505\n",
      "  Precision: -0.0482\n",
      "  Recall: +0.9852\n",
      "\n",
      "Language: TE\n",
      "----------------------------------------\n",
      "Training Set - Class 0: 45, Class 1: 1310\n",
      "Imbalance Ratio: 29.11:1\n",
      "\n",
      "Zero-Shot Performance:\n",
      "  Accuracy: 0.2422\n",
      "  F1: 0.0136\n",
      "  Precision: 0.5000\n",
      "  Recall: 0.0069\n",
      "\n",
      "Fine-Tuned Performance (Balanced):\n",
      "  Accuracy: 0.9297\n",
      "  F1: 0.9551\n",
      "  Precision: 0.9258\n",
      "  Recall: 0.9863\n",
      "\n",
      "Improvements:\n",
      "  Accuracy: +0.6875\n",
      "  F1: +0.9415\n",
      "  Precision: +0.4258\n",
      "  Recall: +0.9794\n",
      "summary\n",
      "Average Improvements Across Languages:\n",
      "  Accuracy: +0.5595\n",
      "  F1: +0.6492\n",
      "  Precision: +0.1658\n",
      "  Recall: +0.6493\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "full_dataset = load_dataset(\"coastalcph/tydi_xor_rc\")\n",
    "\n",
    "model_checkpoint = \"distilbert/distilbert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    tokenized_input = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=512,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    tokenized_input[\"label\"] = [int(ans) for ans in examples[\"answerable\"]]\n",
    "    return tokenized_input\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "def analyze_class_distribution(dataset, lang):\n",
    "    labels = [int(example['answerable']) for example in dataset]\n",
    "    counter = Counter(labels)\n",
    "    total = len(labels)\n",
    "    print(f\"\\n--- Class Distribution for {lang.upper()} ---\")\n",
    "    print(f\"Class 0 (Not Answerable): {counter[0]} ({counter[0]/total:.2%})\")\n",
    "    print(f\"Class 1 (Answerable): {counter[1]} ({counter[1]/total:.2%})\")\n",
    "    print(f\"Imbalance Ratio: {max(counter.values()) / min(counter.values()):.2f}:1\")\n",
    "    return labels\n",
    "\n",
    "def compute_class_weights(labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    class_weights = compute_class_weight('balanced', classes=unique_labels, y=labels)\n",
    "    class_weight_dict = dict(zip(unique_labels, class_weights))\n",
    "    print(f\"Computed class weights: {class_weight_dict}\")\n",
    "    return torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "class WeightedTrainer(Trainer):    \n",
    "    def __init__(self, class_weights=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.class_weights = class_weights\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        if self.class_weights is not None:\n",
    "            weights = self.class_weights.to(logits.device)\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
    "        else:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def apply_focal_loss_trainer(alpha=0.25, gamma=2.0):\n",
    "    class FocalLossTrainer(Trainer):\n",
    "        def __init__(self, alpha=alpha, gamma=gamma, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.alpha = alpha\n",
    "            self.gamma = gamma\n",
    "        def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "            labels = inputs.get(\"labels\")\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.get('logits')\n",
    "            ce_loss = nn.CrossEntropyLoss(reduction='none')(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "            pt = torch.exp(-ce_loss)\n",
    "            focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "            loss = focal_loss.mean()\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "    return FocalLossTrainer\n",
    "\n",
    "languages = ['ar', 'ko', 'te']\n",
    "results = {}\n",
    "\n",
    "for lang in languages:\n",
    "    print(f\"Language: {lang.upper()}\")\n",
    "    train_dataset = full_dataset[\"train\"].filter(lambda example: example['lang'] == lang)\n",
    "    val_dataset = full_dataset[\"validation\"].filter(lambda example: example['lang'] == lang)\n",
    "    train_labels = analyze_class_distribution(train_dataset, f\"{lang}_train\")\n",
    "    val_labels = analyze_class_distribution(val_dataset, f\"{lang}_validation\")\n",
    "    class_weights = compute_class_weights(train_labels)\n",
    "    tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
    "    tokenized_val = val_dataset.map(preprocess_function, batched=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\n",
    "    print(f\"\\nPerforming Zero-Shot Evaluation for {lang.upper()}...\")\n",
    "    zero_shot_trainer = Trainer(\n",
    "        model=model,\n",
    "        eval_dataset=tokenized_val,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    zero_shot_results = zero_shot_trainer.evaluate()\n",
    "    print(f\"Zero-shot results: Acc={zero_shot_results['eval_accuracy']:.4f}, \"\n",
    "          f\"F1={zero_shot_results['eval_f1']:.4f}, \"\n",
    "          f\"Precision={zero_shot_results['eval_precision']:.4f}, \"\n",
    "          f\"Recall={zero_shot_results['eval_recall']:.4f}\")\n",
    "    print(f\"\\nFine-Tuning Model with Class Balancing for {lang.upper()}...\")\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results_{lang}\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        eval_steps=50,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=3,  \n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f'./logs_{lang}',\n",
    "        logging_steps=50,\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_f1\",  \n",
    "        greater_is_better=True,\n",
    "        save_total_limit=2,\n",
    "        dataloader_pin_memory=False, \n",
    "    )\n",
    "    imbalance_ratio = max(Counter(train_labels).values()) / min(Counter(train_labels).values())\n",
    "    if imbalance_ratio > 10:  \n",
    "        print(f\"Severe imbalance detected (ratio: {imbalance_ratio:.2f}:1). Using Focal Loss.\")\n",
    "        TrainerClass = apply_focal_loss_trainer(alpha=0.25, gamma=2.0)\n",
    "        trainer = TrainerClass(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_val,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "    else:  \n",
    "        print(f\"Moderate imbalance detected (ratio: {imbalance_ratio:.2f}:1). Using Class Weights.\")\n",
    "        trainer = WeightedTrainer(\n",
    "            class_weights=class_weights,\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_val,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "    trainer.train()\n",
    "    print(f\"\\nEvaluating Fine-Tuned Model for {lang.upper()}...\")\n",
    "    final_eval_results = trainer.evaluate()\n",
    "    print(f\"Fine-tuned results: Acc={final_eval_results['eval_accuracy']:.4f}, \"\n",
    "          f\"F1={final_eval_results['eval_f1']:.4f}, \"\n",
    "          f\"Precision={final_eval_results['eval_precision']:.4f}, \"\n",
    "          f\"Recall={final_eval_results['eval_recall']:.4f}\")\n",
    "    results[lang] = {\n",
    "        \"zero_shot\": zero_shot_results,\n",
    "        \"fine_tuned\": final_eval_results,\n",
    "        \"class_distribution\": {\n",
    "            \"train\": dict(Counter(train_labels)),\n",
    "            \"val\": dict(Counter(val_labels))\n",
    "        },\n",
    "        \"imbalance_ratio\": imbalance_ratio\n",
    "    }\n",
    "    trainer.save_model(f\"./models/{lang}_fine_tuned\")\n",
    "    tokenizer.save_pretrained(f\"./models/{lang}_fine_tuned\")\n",
    "    print(f\"Model for {lang.upper()} saved to ./models/{lang}_fine_tuned\")\n",
    "\n",
    "for lang, res in results.items():\n",
    "    print(f\"\\nLanguage: {lang.upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    train_dist = res['class_distribution']['train']\n",
    "    print(f\"Training Set - Class 0: {train_dist.get(0, 0)}, Class 1: {train_dist.get(1, 0)}\")\n",
    "    print(f\"Imbalance Ratio: {res['imbalance_ratio']:.2f}:1\")\n",
    "    zs_metrics = res['zero_shot']\n",
    "    ft_metrics = res['fine_tuned']\n",
    "    print(f\"\\nZero-Shot Performance:\")\n",
    "    print(f\"  Accuracy: {zs_metrics['eval_accuracy']:.4f}\")\n",
    "    print(f\"  F1: {zs_metrics['eval_f1']:.4f}\")\n",
    "    print(f\"  Precision: {zs_metrics['eval_precision']:.4f}\")\n",
    "    print(f\"  Recall: {zs_metrics['eval_recall']:.4f}\")\n",
    "    print(f\"\\nFine-Tuned Performance (Balanced):\")\n",
    "    print(f\"  Accuracy: {ft_metrics['eval_accuracy']:.4f}\")\n",
    "    print(f\"  F1: {ft_metrics['eval_f1']:.4f}\")\n",
    "    print(f\"  Precision: {ft_metrics['eval_precision']:.4f}\")\n",
    "    print(f\"  Recall: {ft_metrics['eval_recall']:.4f}\")\n",
    "    print(f\"\\nImprovements:\")\n",
    "    print(f\"  Accuracy: {ft_metrics['eval_accuracy'] - zs_metrics['eval_accuracy']:+.4f}\")\n",
    "    print(f\"  F1: {ft_metrics['eval_f1'] - zs_metrics['eval_f1']:+.4f}\")\n",
    "    print(f\"  Precision: {ft_metrics['eval_precision'] - zs_metrics['eval_precision']:+.4f}\")\n",
    "    print(f\"  Recall: {ft_metrics['eval_recall'] - zs_metrics['eval_recall']:+.4f}\")\n",
    "\n",
    "print(\"summary\")\n",
    "\n",
    "avg_improvements = {\n",
    "    'accuracy': np.mean([res['fine_tuned']['eval_accuracy'] - res['zero_shot']['eval_accuracy'] for res in results.values()]),\n",
    "    'f1': np.mean([res['fine_tuned']['eval_f1'] - res['zero_shot']['eval_f1'] for res in results.values()]),\n",
    "    'precision': np.mean([res['fine_tuned']['eval_precision'] - res['zero_shot']['eval_precision'] for res in results.values()]),\n",
    "    'recall': np.mean([res['fine_tuned']['eval_recall'] - res['zero_shot']['eval_recall'] for res in results.values()])\n",
    "}\n",
    "print(f\"Average Improvements Across Languages:\")\n",
    "for metric, improvement in avg_improvements.items():\n",
    "    print(f\"  {metric.capitalize()}: {improvement:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc51367",
   "metadata": {},
   "source": [
    "## Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdf29430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc5427882cd40d69d5df627a93ddca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/15343 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9852aee72c945ce8165f74ac6521238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3011 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Class Distribution for Combined Train ---\n",
      "Class 0 (Not Answerable): 363 (5.73%)\n",
      "Class 1 (Answerable): 5972 (94.27%)\n",
      "Imbalance Ratio: 16.45:1\n",
      "\n",
      "--- Class Distribution for Combined Validation ---\n",
      "Class 0 (Not Answerable): 164 (14.20%)\n",
      "Class 1 (Answerable): 991 (85.80%)\n",
      "Imbalance Ratio: 6.04:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512de794e5b741bdb5bc45b2aa06c8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6335 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ae6d3608fc4601b164def577183c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "wandb: Currently logged in as: aarushsinha60 (chungimungi) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\aarus\\Desktop\\Github\\DIKU-NLP\\week-38\\wandb\\run-20251005_230308-4f2yxj95</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/chungimungi/huggingface/runs/4f2yxj95' target=\"_blank\">comfy-haze-21</a></strong> to <a href='https://wandb.ai/chungimungi/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/chungimungi/huggingface' target=\"_blank\">https://wandb.ai/chungimungi/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/chungimungi/huggingface/runs/4f2yxj95' target=\"_blank\">https://wandb.ai/chungimungi/huggingface/runs/4f2yxj95</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2376' max='2376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2376/2376 11:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.560200</td>\n",
       "      <td>0.700207</td>\n",
       "      <td>0.950649</td>\n",
       "      <td>0.971656</td>\n",
       "      <td>0.957843</td>\n",
       "      <td>0.985873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.662729</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.972705</td>\n",
       "      <td>0.957031</td>\n",
       "      <td>0.988900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.297700</td>\n",
       "      <td>0.613241</td>\n",
       "      <td>0.950649</td>\n",
       "      <td>0.971712</td>\n",
       "      <td>0.956055</td>\n",
       "      <td>0.987891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='290' max='145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [145/145 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilingual model saved to ./models/multilingual_fine_tuned\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f588188289e644cea7dedc2c28d2fddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3011 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b263553cf78f4726ba26f7bf9fb36dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/415 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation on AR:\n",
      "  Accuracy: 0.9807\n",
      "  F1: 0.9889\n",
      "  Precision: 0.9944\n",
      "  Recall: 0.9835\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1698d5e77f2405ca17cc3a496467f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3011 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd098f4888ee46c5b3aeb59ddbcd2039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/356 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation on KO:\n",
      "  Accuracy: 0.9438\n",
      "  F1: 0.9711\n",
      "  Precision: 0.9465\n",
      "  Recall: 0.9970\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ac6b4fde8d4043a2510000ac2eeb5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3011 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b63a6794f6348968ee384b9228d72d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/384 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation on TE:\n",
      "  Accuracy: 0.9297\n",
      "  F1: 0.9551\n",
      "  Precision: 0.9258\n",
      "  Recall: 0.9863\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "full_dataset = load_dataset(\"coastalcph/tydi_xor_rc\")\n",
    "\n",
    "model_checkpoint = \"distilbert/distilbert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    tokenized_input = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=512,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    tokenized_input[\"label\"] = [int(ans) for ans in examples[\"answerable\"]]\n",
    "    return tokenized_input\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "def analyze_class_distribution(dataset, name):\n",
    "    labels = [int(example['answerable']) for example in dataset]\n",
    "    counter = Counter(labels)\n",
    "    total = len(labels)\n",
    "    print(f\"\\n--- Class Distribution for {name} ---\")\n",
    "    print(f\"Class 0 (Not Answerable): {counter[0]} ({counter[0]/total:.2%})\")\n",
    "    print(f\"Class 1 (Answerable): {counter[1]} ({counter[1]/total:.2%})\")\n",
    "    print(f\"Imbalance Ratio: {max(counter.values()) / min(counter.values()):.2f}:1\")\n",
    "    return labels\n",
    "\n",
    "def compute_class_weights(labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    class_weights = compute_class_weight('balanced', classes=unique_labels, y=labels)\n",
    "    return torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "class WeightedTrainer(Trainer):    \n",
    "    def __init__(self, class_weights=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.class_weights = class_weights\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        if self.class_weights is not None:\n",
    "            weights = self.class_weights.to(logits.device)\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
    "        else:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "all_train = full_dataset[\"train\"].filter(lambda x: x['lang'] in ['ar','ko','te'])\n",
    "all_val = full_dataset[\"validation\"].filter(lambda x: x['lang'] in ['ar','ko','te'])\n",
    "\n",
    "train_labels = analyze_class_distribution(all_train, \"Combined Train\")\n",
    "val_labels = analyze_class_distribution(all_val, \"Combined Validation\")\n",
    "class_weights = compute_class_weights(train_labels)\n",
    "\n",
    "tokenized_train = all_train.map(preprocess_function, batched=True)\n",
    "tokenized_val = all_val.map(preprocess_function, batched=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_multilingual\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs_multilingual',\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_f1\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2,\n",
    "    dataloader_pin_memory=False\n",
    ")\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    class_weights=class_weights,\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "final_eval_results = trainer.evaluate()\n",
    "trainer.save_model(\"./models/multilingual_fine_tuned\")\n",
    "tokenizer.save_pretrained(\"./models/multilingual_fine_tuned\")\n",
    "print(\"Multilingual model saved to ./models/multilingual_fine_tuned\")\n",
    "\n",
    "languages = ['ar', 'ko', 'te']\n",
    "for lang in languages:\n",
    "    lang_val = full_dataset[\"validation\"].filter(lambda x: x['lang'] == lang)\n",
    "    tokenized_lang_val = lang_val.map(preprocess_function, batched=True)\n",
    "    metrics = trainer.evaluate(tokenized_lang_val)\n",
    "    print(f\"\\nEvaluation on {lang.upper()}:\")\n",
    "    print(f\"  Accuracy: {metrics['eval_accuracy']:.4f}\")\n",
    "    print(f\"  F1: {metrics['eval_f1']:.4f}\")\n",
    "    print(f\"  Precision: {metrics['eval_precision']:.4f}\")\n",
    "    print(f\"  Recall: {metrics['eval_recall']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
