{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7134cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "dataset = load_dataset(\"coastalcph/tydi_xor_rc\")\n",
    "\n",
    "languages = ['ar', 'ko', 'te']\n",
    "train = dataset[\"train\"].filter(lambda example: example['lang'] in languages).to_pandas()\n",
    "val = dataset[\"validation\"].filter(lambda example: example['lang'] in languages).to_pandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d7960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenize(sentence):\n",
    "    return re.findall(r\"\\w+\", sentence.lower())\n",
    "\n",
    "class Vocabulary():\n",
    "\n",
    "    \n",
    "    def __init__(self, texts):\n",
    "        counter = Counter()\n",
    "        for t in texts:\n",
    "            counter.update(Tokenize(t))\n",
    "        self.itos = [\"<unk>\", \"<bos>\", \"<sep>\", \"<eos>\"] + [w for w, c in counter.items()]\n",
    "        self.stoi = {w: i for i, w in enumerate(self.itos)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "    \n",
    "    def Encode(self, sentence):\n",
    "        return [self.stoi.get(word, 0) for word in Tokenize(sentence)]\n",
    "    \n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, df, vocab):\n",
    "        self.data = df\n",
    "        self.vocab = vocab\n",
    "    \n",
    "    def __getitem__(self, n):\n",
    "        row = self.data.iloc[n]\n",
    "        question = self.vocab.Encode(row[\"question\"])\n",
    "        context = self.vocab.Encode(row[\"context\"])\n",
    "        x = torch.tensor([1] + question + [2] + context + [3]) \n",
    "        y = torch.tensor(1 if row[\"answerable\"] else 0) \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72d577f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)  # binary classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        _, (h, _) = self.lstm(emb)\n",
    "        h = torch.cat((h[-2], h[-1]), dim=1)  # concat last fwd + bwd\n",
    "        return self.sigmoid(self.fc(h)).squeeze()\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "    xs = pad_sequence(xs, batch_first=True, padding_value=0)\n",
    "    ys = torch.stack(ys)\n",
    "    return xs, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d80c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainLSTM(train, val):\n",
    "    vocab = Vocabulary(train[\"question\"].tolist() + train[\"context\"].tolist())\n",
    "\n",
    "    train_ds = Data(train, vocab)\n",
    "    val_ds = Data(val, vocab)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_ds, batch_size=32, collate_fn=collate_fn)\n",
    "\n",
    "    model = LSTMClassifier(len(vocab))\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        for x, y in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(x)\n",
    "            loss = criterion(preds, y.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}, train loss = {loss.item():.4f}\")\n",
    "\n",
    "    return model , val_loader\n",
    "\n",
    "def ValidateModel(model, val_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            preds = (model(x) > 0.5).long()\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    print(\"Validation accuracy:\", correct / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f23736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [01:09<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss = 0.0232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [01:01<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train loss = 0.2467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [01:12<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, train loss = 0.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [01:05<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, train loss = 0.0836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:55<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, train loss = 0.0205\n",
      "Validation accuracy: 0.9566265060240964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:49<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss = 0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:41<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train loss = 0.1161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:40<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, train loss = 0.0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:45<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, train loss = 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:39<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, train loss = 0.0020\n",
      "Validation accuracy: 0.9353932584269663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:22<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss = 0.5700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:24<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train loss = 0.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:18<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, train loss = 0.0169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:19<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, train loss = 0.1392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:19<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, train loss = 0.0118\n",
      "Validation accuracy: 0.7942708333333334\n"
     ]
    }
   ],
   "source": [
    "model, val_loader = TrainLSTM(train[train[\"lang\"] == \"ar\"], val[val[\"lang\"] == \"ar\"])\n",
    "ValidateModel(model, val_loader)\n",
    "#0.9566\n",
    "model, val_loader = TrainLSTM(train[train[\"lang\"] == \"ko\"], val[val[\"lang\"] == \"ko\"])\n",
    "ValidateModel(model, val_loader)\n",
    "#0.9354\n",
    "model, val_loader = TrainLSTM(train[train[\"lang\"] == \"te\"], val[val[\"lang\"] == \"te\"])\n",
    "ValidateModel(model, val_loader)\n",
    "#0.7943\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
